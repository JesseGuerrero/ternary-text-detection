{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# The pre-trained roberta-based detector may only works w/\n",
    "# - Huggingface version 2.9.1 (i.e., ```transformers==2.9.1```)\n",
    "# - ```tokenizers==0.7.0```\n",
    "# !pip install transformers==2.9.1\n",
    "\n",
    "'''\n",
    "~~~About Checkpoints~~~\n",
    "base.pt is the most accurate checkpoint\n",
    "base_1.pt is the latest checkpoint\n",
    "'''\n",
    "import numpy\n",
    "\n",
    "FROM_CHECKPOINT = False\n",
    "CHECKPOINTNAME = \"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import tqdm\n",
    "# from tqdm.notebook import trange\n",
    "from tqdm import trange\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "import utils as U\n",
    "\n",
    "import sys\n",
    "\n",
    "# setting path\n",
    "sys.path.append('..')\n",
    "\n",
    "from mutation_miniframework.Dataset import *\n",
    "from mutation_miniframework.operators import deleteRandomArticle, replaceLetters, replaceFromDictionary, \\\n",
    "\treplaceWordListWithRandomSelf\n",
    "\n",
    "misspellings = U.loadJSONWordDictionary(\"../mutation_miniframework/mutation_data/misspellings.json\")\n",
    "antonyms = U.loadJSONWordDictionary(\"../mutation_miniframework/mutation_data/antonyms.json\")\n",
    "synonyms = U.loadJSONWordDictionary(\"../mutation_miniframework/mutation_data/misspellings.json\")\n",
    "randomList = []\n",
    "with open(\"../mutation_miniframework/mutation_data/random_word.json\") as randomJSON:\n",
    "    randomBuffer = dict(json.load(randomJSON))\n",
    "    randomList = randomBuffer[\"word\"]\n",
    "\n",
    "project_data_path = \"./test\"\n",
    "\n",
    "text_data_path = os.path.join(project_data_path, 'data_10k', 'Parsed')\n",
    "human_text_dir = os.path.join(text_data_path, 'train_val_test/human')\n",
    "human_mutation_text_dir = os.path.join(text_data_path, 'train_val_test/mutation_human')\n",
    "synthetic_text_dir = os.path.join(text_data_path, 'train_val_test/synthetic')\n",
    "synthetic_mutation_text_dir = os.path.join(text_data_path, 'train_val_test/mutation_synthetic')\n",
    "text_file_human_mutation = 'WikiHumanMutationFullSet.json'\n",
    "text_file_human = 'WikiHumanFullSet.json'\n",
    "text_file_synthetic = 'WikiSyntheticFullSet.json'\n",
    "text_file_synthetic_mutation = 'WikiSyntheticMutationFullSet.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(project_data_path, \"ckpt\")\n",
    "output_path = os.path.join(ckpt_dir, \"Ternary-Custom-Detector\")\n",
    "if(not os.path.exists(output_path)):\n",
    "    print(\"Making Dir...\\n\\t%s\" %output_path)\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "roberta_detector_ckpt_dir = os.path.join(ckpt_dir, 'RoBERTa-Based-Detector')\n",
    "roberta_detector_ckpt_name = 'detector-large.pt'\n",
    "roberta_detector_ckpt_path = os.path.join(roberta_detector_ckpt_dir,\n",
    "                                          roberta_detector_ckpt_name)\n",
    "roberta_detector_ckpt_url = 'https://openaipublic.azureedge.net/gpt-2/detector-models/v1/detector-large.pt'\n",
    "\n",
    "# Download RoBERTa-based Detector ckpt if needed\n",
    "if (not os.path.exists(roberta_detector_ckpt_path)):\n",
    "    if(not os.path.exists(roberta_detector_ckpt_dir)):\n",
    "        print(\"Making Dir...\\n\\t%s\" %roberta_detector_ckpt_dir)\n",
    "        os.makedirs(roberta_detector_ckpt_dir)\n",
    "    U.download_roberta_ckpt(roberta_detector_ckpt_url,\n",
    "                            roberta_detector_ckpt_path)\n",
    "\n",
    "# Load data\n",
    "#[img name, captions, label]\n",
    "train_data = U.load_data(human_text_dir, text_file_human,\n",
    "                         human_mutation_text_dir, text_file_human_mutation,\n",
    "                         synthetic_text_dir, text_file_synthetic,\n",
    "                         synthetic_mutation_text_dir, text_file_synthetic_mutation,\n",
    "                         train_test_split='train')\n",
    "val_data = U.load_data(human_text_dir, text_file_human,\n",
    "                       human_mutation_text_dir, text_file_human_mutation,\n",
    "                       synthetic_text_dir, text_file_synthetic,\n",
    "                       synthetic_mutation_text_dir, text_file_synthetic_mutation,\n",
    "                       train_test_split='val')\n",
    "test_data = U.load_data(human_text_dir, text_file_human,\n",
    "                        human_mutation_text_dir, text_file_human_mutation,\n",
    "                        synthetic_text_dir, text_file_synthetic,\n",
    "                        synthetic_mutation_text_dir, text_file_synthetic_mutation,\n",
    "                        train_test_split='test')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# set hyperparameters\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "learning_rate = 0.0001\n",
    "finetune_embeddings = False\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initiate pre-trained RoBERTa-based Detector\n",
    "ckpt = None\n",
    "if FROM_CHECKPOINT is True:\n",
    "    ckpt = torch.load(os.path.join(output_path, CHECKPOINTNAME))\n",
    "else:\n",
    "    ckpt = torch.load(roberta_detector_ckpt_path) # checkpoint for pre-trained reberta detector, replace here with path.\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-large')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "if FROM_CHECKPOINT is True:\n",
    "    model.load_state_dict(ckpt)#Only do ckpt when loading\n",
    "else:\n",
    "    model.load_state_dict(ckpt['model_state_dict'])#Only do ckpt when loading\n",
    "model = model.to(device)\n",
    "model.classifier.out_proj = nn.Linear(1024, 4, bias=True)\n",
    "\n",
    "# Freeze roberta weights (i.e., the embedding weights)\n",
    "# leave the classifier tunable\n",
    "for p in model.roberta.parameters():\n",
    "    p.requires_grad = finetune_embeddings\n",
    "\n",
    "\n",
    "\n",
    "BCE = nn.BCELoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "## Train Loop ##\n",
    "t = trange(epochs, desc=\"\", position=0, leave=True)\n",
    "\n",
    "phases = [\"train\", \"val\"]\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "train_hist = []\n",
    "val_hist = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch/Step: 0/202900[Phase:train]  Loss:0.7412  CorrectPred:0.6205 [125904/202901]:   0%|          | 0/10 [4:15:51<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-c99c0dc2d1fa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;32mif\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mphase\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"train\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m                 \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m                 \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcur_token_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcur_masks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcur_labels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m                 \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\transformers\\modeling_roberta.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001B[0m\n\u001B[0;32m    332\u001B[0m                                \u001B[0mposition_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    333\u001B[0m                                \u001B[0mhead_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 334\u001B[1;33m                                inputs_embeds=inputs_embeds)\n\u001B[0m\u001B[0;32m    335\u001B[0m         \u001B[0msequence_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    336\u001B[0m         \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msequence_output\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\transformers\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001B[0m\n\u001B[0;32m    731\u001B[0m             \u001B[0mhead_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_hidden_layers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    732\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 733\u001B[1;33m         \u001B[0membedding_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mposition_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs_embeds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs_embeds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    734\u001B[0m         encoder_outputs = self.encoder(embedding_output,\n\u001B[0;32m    735\u001B[0m                                        \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mextended_attention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\transformers\\modeling_roberta.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001B[0m\n\u001B[0;32m     68\u001B[0m                                                       \u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m                                                       \u001B[0mposition_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m                                                       inputs_embeds=inputs_embeds)\n\u001B[0m\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\transformers\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001B[0m\n\u001B[0;32m    188\u001B[0m         \u001B[0membeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs_embeds\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mposition_embeddings\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtoken_type_embeddings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m         \u001B[0membeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLayerNorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 190\u001B[1;33m         \u001B[0membeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    191\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0membeddings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    192\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minplace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MutationCaption1\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mdropout\u001B[1;34m(input, p, training, inplace)\u001B[0m\n\u001B[0;32m   1250\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mp\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0.0\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1.0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1251\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dropout probability has to be between 0 and 1, \"\u001B[0m \u001B[1;34m\"but got {}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1252\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_VF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0minplace\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0m_VF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1253\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1254\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue."
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "for e in t:\n",
    "    model.to(device)\n",
    "    for phase in phases:\n",
    "\n",
    "        ## Initialization ##\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "            data = np.array(train_data)\n",
    "            np.random.shuffle(data)\n",
    "        else:\n",
    "            model.eval()\n",
    "            data = np.array(val_data)\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_correct_pred = 0\n",
    "        step_per_epoch = math.floor(len(data) / batch_size)\n",
    "\n",
    "        ## Train/Val Loop ##\n",
    "        for i in range(step_per_epoch):\n",
    "            # Load one batch of data\n",
    "            # batch size might have to be 1 due to varying caption length\n",
    "            cur_data = data[i*batch_size:(i+1)*batch_size]\n",
    "            cur_names = cur_data[:,0]\n",
    "            cur_captions = cur_data[:,1]#TODO: Adjust for extra dimension, captions and labels\n",
    "            cur_labels = cur_data[:,2].astype(np.int8)#Human Mutation is 0, real is 1, synthetic is 2, mutated synthetic is 3\n",
    "\n",
    "            # Generate mutation\n",
    "            # if need to generate mutation, add code here\n",
    "            # print(\"DATA \" + str(cur_data))\n",
    "            dataDict = {}\n",
    "            if phase == \"train\" and cur_labels == 0 or cur_labels == 3:\n",
    "                dataDict[0] = [str(cur_data[:,1])]\n",
    "                choice = randrange(0, 6)\n",
    "                mutatedCaptionData = Dataset(dataDict, [\"\"])\n",
    "                if choice == 0:\n",
    "                    deleteRandomArticle(mutatedCaptionData, [\" a \", \" an \", \" the \"], \"\", word_change_limit=99)\n",
    "                if choice == 1:\n",
    "                    replaceLetters(mutatedCaptionData, {\n",
    "                        \"a\": \"α\",\n",
    "                        \"e\": \"ε\"\n",
    "                    }, \"\", word_change_limit=6)\n",
    "                if choice == 2:\n",
    "                    replaceFromDictionary(mutatedCaptionData, misspellings, \"\", word_change_limit=5)\n",
    "                if choice == 3:#random word replacement\n",
    "                    replaceWordListWithRandomSelf(mutatedCaptionData, randomList, \"\", word_change_limit=5)\n",
    "                if choice == 4:#synonyms replacement\n",
    "                    replaceFromDictionary(mutatedCaptionData, synonyms, \"\", word_change_limit=5)\n",
    "                if choice == 5:#antonyms replacement\n",
    "                    replaceFromDictionary(mutatedCaptionData, antonyms, \"\", word_change_limit=5)\n",
    "                if choice == 6:\n",
    "                    pass\n",
    "                # print(f'{choice} MUTATION {mutatedCaptionData[0][0]}' )\n",
    "                cur_data[:,1] = mutatedCaptionData[0][0]\n",
    "                cur_captions = cur_data[:,1]\n",
    "            # print(str(choice) + \":\" + str(cur_data[:,1][0]))\n",
    "\n",
    "            # Tokenize captions\n",
    "            cur_token_ids = [tokenizer.encode(item) for item in cur_captions]\n",
    "            cur_masks = [np.ones(len(item)) for item in cur_token_ids]\n",
    "\n",
    "            # Convert to tensor and send data to device\n",
    "            cur_token_ids = torch.tensor(np.array(cur_token_ids)).to(device)\n",
    "            cur_labels = torch.tensor(np.array(cur_labels)).long().to(device)\n",
    "            cur_masks = torch.tensor(np.array(cur_masks)).to(device)\n",
    "\n",
    "            # For training\n",
    "            if(phase == \"train\"):\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(cur_token_ids, attention_mask=cur_masks)\n",
    "                loss = loss_function(logits[0], cur_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # scheduler may be needed in the future\n",
    "\n",
    "            # For validation\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    logits = model(cur_token_ids, attention_mask=cur_masks)\n",
    "                    loss = loss_function(logits[0], cur_labels)\n",
    "\n",
    "            # Track current performance\n",
    "            # Count correct prediciton\n",
    "            for kk in range(len(cur_labels)):\n",
    "                prob = logits[0][kk].softmax(dim=-1)\n",
    "                pred = torch.argmax(prob.detach().cpu())\n",
    "                if(pred==cur_labels[kk]):\n",
    "                    epoch_correct_pred +=  1.0\n",
    "            # Add current loss to total epoch loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            if i % 100 == 0:\n",
    "                t.set_description(\"Epoch/Step: %i/%i[Phase:%s]  Loss:%.4f  CorrectPred:%.4f [%i/%i]\"\n",
    "                              % (e, i, phase, loss.item(), epoch_correct_pred/(i+1), epoch_correct_pred, (i+1)))\n",
    "\n",
    "\n",
    "        ## Compute epoch performance ##\n",
    "        epoch_acc = epoch_correct_pred / (step_per_epoch * batch_size)\n",
    "        epoch_loss = epoch_loss / step_per_epoch\n",
    "\n",
    "        if(phase==\"train\"):\n",
    "            train_hist.append([epoch_loss, epoch_acc])\n",
    "            np.save(os.path.join(output_path,\"train_hist.npy\"),\n",
    "                    np.asarray(train_hist))\n",
    "\n",
    "        else:\n",
    "            val_hist.append([epoch_loss, epoch_acc])\n",
    "            np.save(os.path.join(output_path,\"val_hist.npy\"),\n",
    "                    np.asarray(val_hist))\n",
    "\n",
    "        if(phase == \"val\"):\n",
    "            if(epoch_acc>best_val_acc):\n",
    "                best_val_acc = epoch_acc\n",
    "                best_epoch = e\n",
    "                print(\"Epoch:%d Acc:%.4f higher than the previous best performance\"\n",
    "                      %(e, best_val_acc))\n",
    "                print(\"Saving ckpt...\")\n",
    "                # save the CKPT\n",
    "                torch.save(model.cpu().state_dict(),\n",
    "                           os.path.join(output_path,\"base.pt\"))\n",
    "\n",
    "    print(\"\\nEpoch:%d   Train Loss/Acc: %.4f/%.4f   Val Loss/ACC %.4f/%.4f\"\n",
    "          %(e, train_hist[e][0], train_hist[e][1], val_hist[e][0], val_hist[e][1]))\n",
    "\n",
    "torch.save(model.cpu().state_dict(),\n",
    "           os.path.join(output_path,\"base_\"+str(e)+\".pt\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1)) = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax1.plot([train_hist[e][1]*100 for e in range(epochs)], color='yellow')\n",
    "ax1.plot([val_hist[e][1]*100 for e in range(epochs)], color='green')\n",
    "ax1.set_xticks([x for x in range(0, epochs, 1)])\n",
    "ax1.set_yticks([y for y in range(0, 101, 10)])\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Accuracy(%)\")\n",
    "ax1.legend(['train', 'val'])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
