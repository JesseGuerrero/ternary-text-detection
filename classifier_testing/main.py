import shutil

import numpy as np
from detector import Detector
from attacks import attack
from utils import load_txt, write_txt, load_json_file, get_results, runcmd, load_caption_file, load_standard_json
import os
from tqdm import tqdm
import time
import subprocess

'''
The dataset originally given into this model is 100% synthetic, generated by GPT-2. we are trying to see if they can be fooled for human
There are different types of attacks/experiments organized by keyword in the attacks.py file

EXPERIMENT_NAME is the name of the folder to hold the data files
ADVERSARIAL_TYPE is the type of changes we make to each text.
IMAGES_TO_RUN is the number of image captions to make adversarial.

Adversarial Types:
-'do-nothing': Nothing is done
-'replace-char': Replace homoglyphs below
-'random-order-replace-char': Same as replace char except the input text lines are shuffled
-'misspelling': Replaces certain words with misspellings from misspellings.json.
'''
EXPERIMENT_NAME = "CheckHuman"
CHECK_HUMAN = True
CHECK_BY_IMAGE = True
ADVERSARIAL_TYPE = "do-nothing"
# DATA_FILE = './data/Test_HumanFullSet.json'
# DATA_FILE = './data/Test_MutationFullSetRandomizedMutations.json'
# DATA_FILE = './data/Test_MutationFullSetReplaceAE.json'
# DATA_FILE = './data/Test_MutationFullSetMisspellings.json'
# DATA_FILE = './data/Test_MutationFullSetDeleteArticles.json'
# DATA_FILE = './data/Test_MutationFullReplaceSynonyms.json'
# DATA_FILE = './data/Test_MutationFullReplaceRandomWords.json'
# DATA_FILE = './data/Test_MutationFullReplaceAntonyms.json'
# DATA_FILE = './data/humanCOCO.txt'
#DATA_FILE = './data/fakeTextSmall1.txt'
#DATA_FILE = './data/fakeTextSmall2.txt'
DATA_FILE = './data/xl-1542M-k40.test.jsonl'
DETECTOR_FILE = "./newestCOCOFullSetCombined.pt"
# DETECTOR_FILE = "./detector-large.pt"
HOMOGLYPH_REPLACEMENT = [[' a ', ' Î± ']]
IMAGES_TO_RUN = 100

IMAGES_TO_RUN *= (1 if CHECK_BY_IMAGE else 5) # run 5 captions individually when not by image

def run_experiment(
	homoglyphs, 
	attack_type, 
	detector,
	experiment_name,
	percent_change = None,
	misspelling_dict = None,
	throwout=False):

	start_time = time.time()


	out_path = './experimental_results/' + experiment_name + '/'
	adv_text_path = out_path + 'adv_texts/'
	numerical_results_path = out_path + 'results.txt'
	num_changes_path = out_path +'num_changes.txt'
	if os.path.isdir('./experimental_results/'):
		if os.path.exists(adv_text_path):
			shutil.rmtree(adv_text_path)
		if os.path.exists(out_path):
			shutil.rmtree(out_path)
		if os.path.exists(numerical_results_path):
			open(numerical_results_path, 'w').close()  # Blank out the files
		if os.path.exists(num_changes_path):
			open(num_changes_path, 'w').close()
	if not os.path.isdir('./experimental_results/'):
		os.mkdir("./experimental_results/")
		open("./experimental_results/blank.txt", 'w').close()

	print('Running Experiment: {} ...'.format(experiment_name))

	if not os.path.isdir(out_path):
		os.mkdir(out_path)
		os.mkdir(adv_text_path)

	text_list = []
	if 'xl-1542M-k40' in DATA_FILE:
		text_list = load_json_file(DATA_FILE)
	if 'xl-1542M-k40' not in DATA_FILE:
		if ".json" in DATA_FILE:
			text_list = load_standard_json(DATA_FILE, CHECK_BY_IMAGE)
		else:
			text_list = load_caption_file(DATA_FILE, CHECK_BY_IMAGE)

	_range = tqdm(range(IMAGES_TO_RUN))#len(text_list)))
	i = 0


	for _ in _range:
		text_to_use = detector.tokenizer.decode(
			detector.tokenizer.encode(text_list[i], max_length=detector.tokenizer.max_len))[3:-4]

		adv_text, num_changes = attack(
			text_to_use, homoglyphs, attack_type, percent_change, misspelling_dict, throwout)
		if throwout and (adv_text==text_to_use):
			pass

		else:

			write_txt(adv_text_path+str(i)+'.txt', adv_text)

			probs = detector.predict(adv_text)

			human_prob = probs[1]

			_range.set_description('{} | {}'.format(i, human_prob))

			with open(numerical_results_path, 'a') as f:
				f.write(str(human_prob) + ' ')
			f.close()

			with open(num_changes_path, 'a') as f:
				f.write(str(num_changes)+' ')
			f.close()
		i+=1
	end_time = time.time()

	print('Time to complete experiment (minutes):', (end_time-start_time)/60.)


import wget
if __name__ == '__main__':
	if not os.path.exists(DETECTOR_FILE):
		print("Downloading detector...")
		wget.download("https://openaipublic.azureedge.net/gpt-2/detector-models/v1/detector-large.pt")
	detector = Detector(DETECTOR_FILE)

	run_experiment(
		HOMOGLYPH_REPLACEMENT,
		ADVERSARIAL_TYPE,
		detector,
		EXPERIMENT_NAME,
		None,
		None,
		None)

	get_results(EXPERIMENT_NAME, CHECK_HUMAN)
