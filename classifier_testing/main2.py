import shutil

import numpy as np
from detector import Detector
from attacks import attack
from utils2 import load_json_file, get_results, load_caption_file, load_standard_json
import os
from tqdm import tqdm
import time

'''
The dataset originally given into this model is 100% synthetic, generated by GPT-2. we are trying to see if they can be fooled for human
There are different types of attacks/experiments organized by keyword in the attacks.py file

EXPERIMENT_NAME is the name of the folder to hold the data files
ADVERSARIAL_TYPE is the type of changes we make to each text.
IMAGES_TO_RUN is the number of image captions to make adversarial.

Adversarial Types:
-'do-nothing': Nothing is done
-'replace-char': Replace homoglyphs below
-'random-order-replace-char': Same as replace char except the input text lines are shuffled
-'misspelling': Replaces certain words with misspellings from misspellings.json.
'''
MUTATION, REAL, SYNTHETIC = 0, 1, 2

EXPERIMENT_NAME = "CheckHuman345"
DATASET_TYPE = REAL
CHECK_BY_IMAGE = True
ADVERSARIAL_TYPE = "do-nothing"
# DATA_FILE = './data/Test_HumanFullSet.json'
# DATA_FILE = './data/Test_MutationFullSetRandomizedMutations.json'
# DATA_FILE = './data/Test_MutationFullSetReplaceAE.json'
# DATA_FILE = './data/Test_MutationFullSetMisspellings.json'
# DATA_FILE = './data/Test_MutationFullSetDeleteArticles.json'
# DATA_FILE = './data/Test_MutationFullReplaceSynonyms.json'
# DATA_FILE = './data/Test_MutationFullReplaceRandomWords.json'
# DATA_FILE = './data/Test_MutationFullReplaceAntonyms.json'
# DATA_FILE = './data/humanCOCO.txt'
DATA_FILE = './data/Val_WikiHuman.json'
#DATA_FILE = './data/fakeTextSmall1.txt'
#DATA_FILE = './data/fakeTextSmall2.txt'
# DATA_FILE = './data/xl-1542M-k40.test.jsonl'
# DETECTOR_FILE = "./newestCOCOFullSetCombined.pt"
DETECTOR_FILE = "./base_9.pt"
HOMOGLYPH_REPLACEMENT = [[' a ', ' Î± ']]
TEXTS_TO_RUN = 10

TEXTS_TO_RUN *= (1 if CHECK_BY_IMAGE else 5) # run 5 captions individually when not by image
adv_textList = []
results = []
num_ch = []
def run_experiment(
	homoglyphs, 
	attack_type, 
	detector,
	experiment_name,
	percent_change = None,
	misspelling_dict = None,
	throwout=False):
	global adv_textList, results, num_ch
	start_time = time.time()

	print('Running Experiment: {} ...'.format(experiment_name))

	text_list = []
	if 'xl-1542M-k40' in DATA_FILE:
		text_list = load_json_file(DATA_FILE)
	if 'xl-1542M-k40' not in DATA_FILE:
		if ".json" in DATA_FILE:
			text_list = load_standard_json(DATA_FILE, CHECK_BY_IMAGE)
		else:
			text_list = load_caption_file(DATA_FILE, CHECK_BY_IMAGE)

	_range = tqdm(range(TEXTS_TO_RUN))#len(text_list)))
	i = 0


	for _ in _range:
		text_to_use = detector.tokenizer.decode(
			detector.tokenizer.encode(text_list[i], max_length=detector.tokenizer.max_len))[3:-4]

		adv_text, num_changes = attack(
			text_to_use, homoglyphs, attack_type, percent_change, misspelling_dict, throwout)
		if throwout and (adv_text==text_to_use):
			pass

		else:

			adv_textList.append(adv_text)
			probs = detector.predict(adv_text)
			pred = probs.tolist().index(max(probs))

			_range.set_description('{} | {}'.format(i, pred))

			results.append(str(pred))
			num_ch.append(str(num_changes))

		i+=1
	end_time = time.time()

	print('Time to complete experiment (minutes):', (end_time-start_time)/60.)


import wget
if __name__ == '__main__':
	detector = Detector(DETECTOR_FILE)

	run_experiment(
		HOMOGLYPH_REPLACEMENT,
		ADVERSARIAL_TYPE,
		detector,
		EXPERIMENT_NAME,
		None,
		None,
		None)

	get_results(EXPERIMENT_NAME, DATASET_TYPE, adv_textList, results, num_ch)
